name: Deploy & Run on Databricks

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  run-etl:
    runs-on: ubuntu-latest

    steps:
    - name: Check out code
      uses: actions/checkout@v3

    - name: Import notebook to Databricks
      run: |
        b64_content=$(base64 -w0 etl_srbija.py)
        cat >payload.json <<EOF
        {
          "path": "/Users/emil.kajkus/etl/etl_srbija.py",
          "language": "PYTHON",
          "format": "SOURCE",
          "content": "$b64_content",
          "overwrite": true
        }
        EOF

        curl -f -X POST "$DATABRICKS_HOST/api/2.0/workspace/import" \
          -H "Authorization: Bearer $DATABRICKS_TOKEN" \
          -H "Content-Type: application/json" \
          --data @payload.json
      env:
        DATABRICKS_HOST:  ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

    - name: Run notebook
      run: |
        curl -f -X POST "$DATABRICKS_HOST/api/2.1/jobs/run-submit" \
          -H "Authorization: Bearer $DATABRICKS_TOKEN" \
          -H "Content-Type: application/json" \
          -d @job-payload.json
      env:
        DATABRICKS_HOST:  ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

